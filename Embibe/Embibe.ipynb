{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Cohorts for a set of Users\n",
    "\n",
    "## Cohorts Analysis \n",
    "Cohort analysis is a subset of behavioral analytics that takes the data from a given data set (e.g. an e-commerce platform, web application, or online game) and rather than looking at all users as one unit, it breaks them into related groups for analysis. These related groups, or cohorts, usually share common characteristics or experiences within a defined time-span.  \n",
    "\n",
    "Reference Link: [Wikepedia](https://en.wikipedia.org/wiki/Cohort_analysis)\n",
    "\n",
    "\n",
    "## Table of content\n",
    "- Generate Sample Data\n",
    "- Categorizing the users into 3 cohorts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate Sample Data\n",
    "\n",
    "##### Problem Statement\n",
    "- Generate random event timestamps (in a 6 month data range) for each user\n",
    "- **Sessions** have multiple events from the same user within it\n",
    "- Users can have multiple sessions(with events within a session) in a single day\n",
    "- Sessions need to be  **time-bounded**\n",
    "\n",
    "Session ??  \n",
    "time-bounded ?? like studied for like 4 hr or such in a day and triggered event in it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random, time, os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of Data points to generate\n",
    "# noOfOberavation = 10000\n",
    "# noOfUsers, noOfEvents = 5000, 25\n",
    "noOfOberavation = 10000\n",
    "noOfUsers, noOfEvents = 10, 3\n",
    "\n",
    "## Config # observation older than\n",
    "n_days = 3 ## in place of 30 days\n",
    "\n",
    "## Data will be generated for 180Days\n",
    "\n",
    "localDataSavingName = 'dataset_Generated_10000_10_3.csv'\n",
    "\n",
    "def strTimeProp(nodaysBefore, end, format, prop):\n",
    "    \"\"\"Get a time at a proportion of a range of two formatted times.\n",
    "\n",
    "    start and end should be strings specifying times formated in the\n",
    "    given format (strftime-style), giving an interval [start, end].\n",
    "    prop specifies how a proportion of the interval to be taken after\n",
    "    start.  The returned time will be in the specified format.\n",
    "    \"\"\"\n",
    "    start = datetime.strptime(end, format) - timedelta(days=nodaysBefore)\n",
    "    stime = time.mktime(time.strptime(start.strftime(format), format))\n",
    "    etime = time.mktime(time.strptime(end, format))\n",
    "    ptime = stime + prop * (etime - stime)\n",
    "    return time.strftime(format, time.localtime(ptime))\n",
    "\n",
    "def randomDate(nodaysBefore, end, prop):\n",
    "    return strTimeProp(nodaysBefore, end, '%Y-%m-%d %H:%M:%S', prop)\n",
    "\n",
    "def randomEvent(totalEvent):\n",
    "    ''' returns an random Event from the totall possible random event '''\n",
    "    return 'event' + str(random.randint(1,totalEvent))\n",
    "\n",
    "def randomUser(totalUser):\n",
    "    return 'u' + str(random.randint(1,totalUser))\n",
    "    \n",
    "    \n",
    "def randomDatasetGenerator():\n",
    "    \n",
    "    eventDict = {'userId': randomUser(noOfUsers),\n",
    "                 'eventTime': randomDate(180, datetime.now().strftime('%Y-%m-%d %H:%M:%S'), random.random()),\n",
    "                'eventId': randomEvent(noOfEvents)\n",
    "                }\n",
    "    return eventDict\n",
    "    \n",
    "#randomDatasetGenerator()\n",
    "if os.path.exists(localDataSavingName):\n",
    "    DF = pd.read_csv(localDataSavingName)\n",
    "else:\n",
    "    DF = pd.DataFrame(columns= ['userId', 'eventTime', 'eventId'])\n",
    "    for i in range(noOfOberavation):\n",
    "        tempDF = pd.DataFrame(randomDatasetGenerator(), index=[0])\n",
    "        DF = DF.append(tempDF, ignore_index=True,sort=False)\n",
    "\n",
    "    DF.sort_values(by=['eventTime'], inplace=True)\n",
    "    DF.reset_index(drop=True,  inplace=True)\n",
    "\n",
    "    display(DF.tail())\n",
    "    # DF.to_csv('dataset_Generated.csv', index=False)\n",
    "    DF.to_csv(localDataSavingName, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorizing users into 3 cohorts\n",
    "* **Active Users (AU)**: Any user who was active at some point of time in last 30 days\n",
    "* **Engaged Users (EU)**: user with >= 1 hour timespent in last 30 days (may have <40 sessions, but total timespent >= 1 hr)\n",
    "* **Power Users (PU)**: user with >= 40 sessions in Embibe in last 30 days\n",
    "* **Ultra Power Users (UPU)**: user with >= 100 sessions in Embibe in last 30 days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session ?? ---  Assume --\n",
    "- if even a single event has occured in a day then, will consider at least a single seesion has been present \n",
    "- in a single day if the tiime diffrence is more than some ammount then distinct session -->  Not Taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset time Type <class 'str'>\n",
      "Dataset time Type <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "(10000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>eventTime</th>\n",
       "      <th>eventId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u2</td>\n",
       "      <td>2018-08-18 19:41:52</td>\n",
       "      <td>event1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u8</td>\n",
       "      <td>2018-08-18 20:24:00</td>\n",
       "      <td>event1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u10</td>\n",
       "      <td>2018-08-18 20:30:06</td>\n",
       "      <td>event2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u2</td>\n",
       "      <td>2018-08-18 21:02:25</td>\n",
       "      <td>event3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u1</td>\n",
       "      <td>2018-08-18 21:45:24</td>\n",
       "      <td>event1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId           eventTime eventId\n",
       "0     u2 2018-08-18 19:41:52  event1\n",
       "1     u8 2018-08-18 20:24:00  event1\n",
       "2    u10 2018-08-18 20:30:06  event2\n",
       "3     u2 2018-08-18 21:02:25  event3\n",
       "4     u1 2018-08-18 21:45:24  event1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## session\n",
    "print('Dataset time Type', type(DF.loc[:,'eventTime'][0]))\n",
    "\n",
    "## converting to datetime\n",
    "DF['eventTime'] = [ datetime.strptime(ele, '%Y-%m-%d %H:%M:%S') for ele in DF['eventTime'] ]\n",
    "\n",
    "print('Dataset time Type', type(DF.loc[:,'eventTime'][0]))\n",
    "print(DF.shape)\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique users: 10\n"
     ]
    }
   ],
   "source": [
    "uniqueUsers = DF['userId'].unique()\n",
    "print('Number of Unique users:', len(uniqueUsers))\n",
    "\n",
    "## Transforming adding a column date\n",
    "DF['date'] = [ datetime.strptime(ele.strftime('%Y-%m-%d'), '%Y-%m-%d') for ele in DF['eventTime'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datset Shape: (10, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>noOfSessions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u1</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u10</td>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u2</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u3</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u4</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId  noOfSessions\n",
       "0     u1          1022\n",
       "1    u10           929\n",
       "2     u2           970\n",
       "3     u3          1029\n",
       "4     u4          1027"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Number of Session held by user\n",
    "SessionCountPerUser = DF.groupby('userId').date.count()\n",
    "UserSessionsDF = pd.DataFrame(SessionCountPerUser).reset_index()\n",
    "UserSessionsDF.rename(columns={'date':'noOfSessions'}, inplace=True)\n",
    "print('Datset Shape:', UserSessionsDF.shape)\n",
    "UserSessionsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datset Shape: (1800, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>date</th>\n",
       "      <th>eventTimeMax</th>\n",
       "      <th>eventTimeMin</th>\n",
       "      <th>timeSpend_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u1</td>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>2018-08-18 21:45:24</td>\n",
       "      <td>2018-08-18 21:45:24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u1</td>\n",
       "      <td>2018-08-19</td>\n",
       "      <td>2018-08-19 17:05:58</td>\n",
       "      <td>2018-08-19 00:12:40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u1</td>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>2018-08-20 22:51:41</td>\n",
       "      <td>2018-08-20 04:37:07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u1</td>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>2018-08-21 23:52:13</td>\n",
       "      <td>2018-08-21 03:45:44</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u1</td>\n",
       "      <td>2018-08-22</td>\n",
       "      <td>2018-08-22 19:22:52</td>\n",
       "      <td>2018-08-22 03:18:22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId       date        eventTimeMax        eventTimeMin  timeSpend_sec\n",
       "0     u1 2018-08-18 2018-08-18 21:45:24 2018-08-18 21:45:24            0.0\n",
       "1     u1 2018-08-19 2018-08-19 17:05:58 2018-08-19 00:12:40            0.0\n",
       "2     u1 2018-08-20 2018-08-20 22:51:41 2018-08-20 04:37:07            0.0\n",
       "3     u1 2018-08-21 2018-08-21 23:52:13 2018-08-21 03:45:44            0.0\n",
       "4     u1 2018-08-22 2018-08-22 19:22:52 2018-08-22 03:18:22            0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## time spend by each user per day on embibe\n",
    "'''\n",
    "= last event on that day - first event on that day\n",
    "'''\n",
    "userDay = DF.groupby(['userId', 'date']).eventTime\n",
    "tempDF_Max = pd.DataFrame(userDay.max()).reset_index()\n",
    "tempDF_Max.rename(columns={'eventTime': 'eventTimeMax'}, inplace=True)\n",
    "tempDF_Min = pd.DataFrame(userDay.min()).reset_index()\n",
    "tempDF_Min.rename(columns={'eventTime': 'eventTimeMin'}, inplace=True)\n",
    "tempDF = pd.merge(tempDF_Max, tempDF_Min, on=['userId', 'date'])\n",
    "temp = [ tempDF['eventTimeMax'][ind] - tempDF['eventTimeMax'][ind] for ind in range(len(tempDF)) ]\n",
    "tempDF['timeSpend_sec'] = [ ele.total_seconds() for ele in temp ]\n",
    "\n",
    "print('Datset Shape:', tempDF.shape)\n",
    "tempDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datset Shape: (10, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>timeSpend_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId  timeSpend_sec\n",
       "0     u1            0.0\n",
       "1    u10            0.0\n",
       "2     u2            0.0\n",
       "3     u3            0.0\n",
       "4     u4            0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Total timespend by user\n",
    "totTimeSpendDF = pd.DataFrame(tempDF.groupby('userId').timeSpend_sec.sum()).reset_index()\n",
    "print('Datset Shape:', totTimeSpendDF.shape)\n",
    "display(totTimeSpendDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluateTimeSpendAndSessions(smallDF):\n",
    "    '''\n",
    "    dropped  user ID\n",
    "    '''\n",
    "    noOfSess = smallDF.date.count()\n",
    "    \n",
    "    userDay = smallDF.groupby(['date']).eventTime\n",
    "    tempDF_Max = pd.DataFrame(userDay.max()).reset_index()\n",
    "    tempDF_Max.rename(columns={'eventTime': 'eventTimeMax'}, inplace=True)\n",
    "    tempDF_Min = pd.DataFrame(userDay.min()).reset_index()\n",
    "    tempDF_Min.rename(columns={'eventTime': 'eventTimeMin'}, inplace=True)\n",
    "    tempDF = pd.merge(tempDF_Max, tempDF_Min, on=['date'])\n",
    "    temp = [ tempDF['eventTimeMax'][ind] - tempDF['eventTimeMax'][ind] for ind in range(len(tempDF)) ]\n",
    "    tempDF['timeSpend_sec'] = [ ele.total_seconds() for ele in temp ]\n",
    "    totTimeSpend = tempDF.timeSpend_sec.sum()\n",
    "    \n",
    "    return noOfSess, totTimeSpend\n",
    "\n",
    "DF['timespendinLast30Days'] = [ 0.0 for i in range(len(DF)) ]\n",
    "DF['noOfSessioninLast30Days'] = [ 0.0 for i in range(len(DF)) ]\n",
    "DF['userCohort'] = [ '-' for i in range(len(DF)) ]\n",
    "\n",
    "for user in uniqueUsers:\n",
    "    userSpecificDF = DF.loc[DF['userId']== user, :]\n",
    "    for index, row in userSpecificDF.iterrows():\n",
    "        # print('Processing  for user', user)\n",
    "        satisf = [ ele <= row['eventTime'] - timedelta(days=n_days) for ele in userSpecificDF['date'] ]\n",
    "        tempDF = userSpecificDF.loc[satisf, ['eventTime', 'eventId', 'date']]\n",
    "        if len(tempDF) != 0:\n",
    "            noOfSess_last30, totTimeSpendDF_last30 =evaluateTimeSpendAndSessions(tempDF)\n",
    "        else:\n",
    "            noOfSess_last30, totTimeSpendDF_last30 = 0, 0\n",
    "        DF.loc[((DF['userId']==user)&(DF['date']==row['date'])), 'noOfSessioninLast30Days'] = noOfSess_last30\n",
    "        DF.loc[((DF['userId']==user)&(DF['date']==row['date'])), 'timespendinLast30Days'] = totTimeSpendDF_last30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giveCohart(row):\n",
    "    ''' '''\n",
    "    if row['noOfSessioninLast30Days'] >= 100:\n",
    "        return 'UPU'\n",
    "    elif row['noOfSessioninLast30Days'] >= 40:\n",
    "        return 'PU'\n",
    "    elif row['timespendinLast30Days'] > 3600.0: # an hour\n",
    "        return 'EU'\n",
    "    elif row['noOfSessioninLast30Days'] > 0:\n",
    "        return 'AU'\n",
    "    else:\n",
    "        return '-'\n",
    "        \n",
    "\n",
    "li = []\n",
    "for index, row in DF.iterrows():\n",
    "    li.append(giveCohart(row))\n",
    "\n",
    "DF['userCohort'] = li "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>eventTime</th>\n",
       "      <th>eventId</th>\n",
       "      <th>date</th>\n",
       "      <th>timespendinLast30Days</th>\n",
       "      <th>noOfSessioninLast30Days</th>\n",
       "      <th>userCohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>u9</td>\n",
       "      <td>2019-02-14 17:06:59</td>\n",
       "      <td>event3</td>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>UPU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>u2</td>\n",
       "      <td>2019-02-14 17:42:35</td>\n",
       "      <td>event3</td>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>UPU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>u10</td>\n",
       "      <td>2019-02-14 18:06:35</td>\n",
       "      <td>event2</td>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>UPU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>u2</td>\n",
       "      <td>2019-02-14 18:19:59</td>\n",
       "      <td>event1</td>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>UPU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>u4</td>\n",
       "      <td>2019-02-14 18:34:41</td>\n",
       "      <td>event1</td>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>UPU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId           eventTime eventId       date  timespendinLast30Days  \\\n",
       "9995     u9 2019-02-14 17:06:59  event3 2019-02-14                    0.0   \n",
       "9996     u2 2019-02-14 17:42:35  event3 2019-02-14                    0.0   \n",
       "9997    u10 2019-02-14 18:06:35  event2 2019-02-14                    0.0   \n",
       "9998     u2 2019-02-14 18:19:59  event1 2019-02-14                    0.0   \n",
       "9999     u4 2019-02-14 18:34:41  event1 2019-02-14                    0.0   \n",
       "\n",
       "      noOfSessioninLast30Days userCohort  \n",
       "9995                   1011.0        UPU  \n",
       "9996                    949.0        UPU  \n",
       "9997                    908.0        UPU  \n",
       "9998                    949.0        UPU  \n",
       "9999                   1011.0        UPU  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(DF.tail())\n",
    "DF.to_csv('result_dataset_Generated_10000_10_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out Day by Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 2018-08-18 --- user1 was -\n",
      "on 2018-08-21 --- user1 was AU\n",
      "on 2018-08-27 --- user1 was PU\n",
      "on 2018-09-06 --- user1 was UPU\n",
      "on 2018-08-18 --- user10 was -\n",
      "on 2018-08-21 --- user10 was AU\n",
      "on 2018-08-30 --- user10 was PU\n",
      "on 2018-09-12 --- user10 was UPU\n",
      "on 2018-08-18 --- user2 was -\n",
      "on 2018-08-21 --- user2 was AU\n",
      "on 2018-08-27 --- user2 was PU\n",
      "on 2018-09-09 --- user2 was UPU\n",
      "on 2018-08-19 --- user3 was -\n",
      "on 2018-08-22 --- user3 was AU\n",
      "on 2018-08-28 --- user3 was PU\n",
      "on 2018-09-06 --- user3 was UPU\n",
      "on 2018-08-18 --- user4 was -\n",
      "on 2018-08-21 --- user4 was AU\n",
      "on 2018-08-27 --- user4 was PU\n",
      "on 2018-09-06 --- user4 was UPU\n",
      "on 2018-08-19 --- user5 was -\n",
      "on 2018-08-22 --- user5 was AU\n",
      "on 2018-08-27 --- user5 was PU\n",
      "on 2018-09-10 --- user5 was UPU\n",
      "on 2018-08-18 --- user6 was -\n",
      "on 2018-08-21 --- user6 was AU\n",
      "on 2018-08-29 --- user6 was PU\n",
      "on 2018-09-13 --- user6 was UPU\n",
      "on 2018-08-19 --- user7 was -\n",
      "on 2018-08-22 --- user7 was AU\n",
      "on 2018-08-29 --- user7 was PU\n",
      "on 2018-09-08 --- user7 was UPU\n",
      "on 2018-08-18 --- user8 was -\n",
      "on 2018-08-21 --- user8 was AU\n",
      "on 2018-08-30 --- user8 was PU\n",
      "on 2018-09-08 --- user8 was UPU\n",
      "on 2018-08-18 --- user9 was -\n",
      "on 2018-08-21 --- user9 was AU\n",
      "on 2018-08-29 --- user9 was PU\n",
      "on 2018-09-08 --- user9 was UPU\n"
     ]
    }
   ],
   "source": [
    "## print day-by-day usage cohort standings\n",
    "li = []\n",
    "DF.sort_values(by=['userId',  'date'], inplace=True)\n",
    "userMsgNew, userMsgNext = '', ''\n",
    "for index, row in DF.iterrows():\n",
    "    userMsgNew = ' --- user'+ str(row['userId'].split('u')[-1]) + ' was ' + str(row['userCohort'])\n",
    "    if userMsgNew != userMsgNext:\n",
    "        string = 'on '+ str(row['date'].strftime('%Y-%m-%d'))+ userMsgNew\n",
    "        li.append(string)\n",
    "    userMsgNext = userMsgNew\n",
    "\n",
    "li = pd.Series(li).unique()\n",
    "for i in range(len(li)):\n",
    "    print(li[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>userCohort</th>\n",
       "      <th>nUniqueUserId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2019-02-10</td>\n",
       "      <td>UPU</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>UPU</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>UPU</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>UPU</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>UPU</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date userCohort  nUniqueUserId\n",
       "187 2019-02-10        UPU             10\n",
       "188 2019-02-11        UPU             10\n",
       "189 2019-02-12        UPU             10\n",
       "190 2019-02-13        UPU             10\n",
       "191 2019-02-14        UPU             10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print day-by-day usage cohort standings\n",
    "\n",
    "uniqueDate = pd.Series([str(ele.strftime('%Y-%m-%d')) for ele in DF['date']]).unique()\n",
    "\n",
    "valDF = DF.groupby(['date', 'userCohort']).userId.nunique().reset_index()\n",
    "valDF.rename(columns={'userId': 'nUniqueUserId'}, inplace=True)\n",
    "valDF.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 2018-08-18\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:0\n",
      "on 2018-08-19\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:0\n",
      "on 2018-08-20\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:0\n",
      "on 2018-08-21\n",
      " \t\t AU: 7, EU: 0, PU: 0, UPU:0\n",
      "on 2018-08-22\n",
      " \t\t AU: 10, EU: 0, PU: 0, UPU:0\n",
      "on 2018-08-23\n",
      " \t\t AU: 10, EU: 0, PU: 0, UPU:0\n",
      "on 2018-08-24\n",
      " \t\t AU: 10, EU: 0, PU: 0, UPU:0\n",
      "on 2018-08-25\n",
      " \t\t AU: 10, EU: 0, PU: 0, UPU:0\n",
      "on 2018-08-26\n",
      " \t\t AU: 10, EU: 0, PU: 0, UPU:0\n",
      "on 2018-08-27\n",
      " \t\t AU: 6, EU: 0, PU: 4, UPU:0\n",
      "on 2018-08-28\n",
      " \t\t AU: 5, EU: 0, PU: 5, UPU:0\n",
      "on 2018-08-29\n",
      " \t\t AU: 2, EU: 0, PU: 8, UPU:0\n",
      "on 2018-08-30\n",
      " \t\t AU: 0, EU: 0, PU: 10, UPU:0\n",
      "on 2018-08-31\n",
      " \t\t AU: 0, EU: 0, PU: 10, UPU:0\n",
      "on 2018-09-01\n",
      " \t\t AU: 0, EU: 0, PU: 10, UPU:0\n",
      "on 2018-09-02\n",
      " \t\t AU: 0, EU: 0, PU: 10, UPU:0\n",
      "on 2018-09-03\n",
      " \t\t AU: 0, EU: 0, PU: 10, UPU:0\n",
      "on 2018-09-04\n",
      " \t\t AU: 0, EU: 0, PU: 10, UPU:0\n",
      "on 2018-09-05\n",
      " \t\t AU: 0, EU: 0, PU: 10, UPU:0\n",
      "on 2018-09-06\n",
      " \t\t AU: 0, EU: 0, PU: 7, UPU:3\n",
      "on 2018-09-07\n",
      " \t\t AU: 0, EU: 0, PU: 7, UPU:3\n",
      "on 2018-09-08\n",
      " \t\t AU: 0, EU: 0, PU: 4, UPU:6\n",
      "on 2018-09-09\n",
      " \t\t AU: 0, EU: 0, PU: 3, UPU:7\n",
      "on 2018-09-10\n",
      " \t\t AU: 0, EU: 0, PU: 2, UPU:8\n",
      "on 2018-09-11\n",
      " \t\t AU: 0, EU: 0, PU: 2, UPU:7\n",
      "on 2018-09-12\n",
      " \t\t AU: 0, EU: 0, PU: 1, UPU:9\n",
      "on 2018-09-13\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-14\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-15\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-16\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-17\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-18\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-19\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-20\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-21\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-22\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-23\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-24\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-25\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-26\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-27\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-28\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-29\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-09-30\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-01\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-02\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-03\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-04\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-05\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-06\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-07\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-08\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-09\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-10\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-11\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-12\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-13\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-14\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-15\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-16\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:9\n",
      "on 2018-10-18\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-20\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-21\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-22\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-23\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-24\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-25\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-26\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-27\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-28\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-29\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-30\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-31\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-01\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-02\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-03\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-04\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-05\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-06\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-07\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-08\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-09\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-10\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-11\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-12\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-13\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-14\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-15\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-16\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-17\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-18\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-19\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-20\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-21\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-22\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-23\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-24\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-25\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-26\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-27\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-28\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-29\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-11-30\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-01\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-02\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-03\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-04\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-05\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-06\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-07\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-08\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-09\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-10\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-11\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-12\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-13\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-14\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-15\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-16\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-17\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-18\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-19\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-20\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-21\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-22\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-23\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-24\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-25\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-26\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-27\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-28\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-29\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-30\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-12-31\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-01\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-02\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-03\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-04\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-05\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-06\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-07\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-08\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-09\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-10\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-11\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:9\n",
      "on 2019-01-12\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:9\n",
      "on 2019-01-13\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-14\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-15\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-16\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-17\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-18\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-19\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-20\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:9\n",
      "on 2019-01-21\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-22\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-23\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-24\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-25\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-26\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-27\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-28\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-29\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-30\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-01-31\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-02-01\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-02-02\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-02-03\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-02-04\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-02-05\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-02-06\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-02-07\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-02-08\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-02-09\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-02-10\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-02-11\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-02-12\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-02-13\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2019-02-14\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:10\n",
      "on 2018-10-17\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:9\n",
      "on 2018-10-19\n",
      " \t\t AU: 0, EU: 0, PU: 0, UPU:9\n"
     ]
    }
   ],
   "source": [
    "def asta(date):\n",
    "    ctr = valDF.loc[valDF['date'] == date, ['userCohort', 'nUniqueUserId']]\n",
    "    au = ctr.loc[ctr['userCohort'] == 'AU', 'nUniqueUserId']\n",
    "    eu = ctr.loc[ctr['userCohort'] == 'EU', 'nUniqueUserId']\n",
    "    pu = ctr.loc[ctr['userCohort'] =='PU', 'nUniqueUserId']\n",
    "    upu = ctr.loc[ctr['userCohort'] == 'UPU', 'nUniqueUserId']\n",
    "    \n",
    "    au = list(au)[0] if len(au) == 1 else 0\n",
    "    eu = list(eu)[0] if len(eu) == 1 else 0\n",
    "    pu = list(pu)[0] if len(pu) == 1 else 0\n",
    "    upu = list(upu)[0] if len(upu) == 1 else 0\n",
    "    \n",
    "    return au, eu, pu, upu\n",
    "\n",
    "\n",
    "for date in uniqueDate:\n",
    "    au, eu, pu, upu = asta(date)\n",
    "    string = 'on '+ str(date)+ '\\n \\t\\t AU: {}, EU: {}, PU: {}, UPU:{}'.format(au, eu, pu, upu)\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "achint@embibe.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyProjectVirEnv",
   "language": "python",
   "name": "myprojectvirenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
